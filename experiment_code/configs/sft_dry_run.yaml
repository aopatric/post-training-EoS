experiment_name: "sft_dry_run"
model_name: "EleutherAI/pythia-70m"
dataset_name: "alpaca"
max_steps: 5
eval_interval: 2
save_interval: 10
batch_size: 2
learning_rate: 1e-4
optimizer: "adamw"
use_lora: true
lora_r: 4
subsample_size: 10
